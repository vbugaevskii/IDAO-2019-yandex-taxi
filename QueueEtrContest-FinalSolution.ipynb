{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDAO: expected time of orders in airports\n",
    "\n",
    "Airports are special points for taxi service. Every day a lot of people use a taxi to get to the city centre from the airport.\n",
    "\n",
    "One of important task is to predict how long a driver need to wait an order. It helps to understand what to do. Maybe the driver have to wait near doors, or can drink a tea, or even should drive to city center without an order.\n",
    "\n",
    "We request you to solve a simple version of this prediction task.\n",
    "\n",
    "**Task:** predict time of $k$ orders in airport (time since now when you get an order if you are $k$-th in queue), $k$ is one of 5 values (different for every airports).\n",
    "\n",
    "**Data**\n",
    "- train: number of order for every minutes for 6 months\n",
    "- test: every test sample has datetime info + numer of order for every minutes for last 2 weeks\n",
    "\n",
    "**Submission:** for every airport you should prepare a model which will be evaluated in submission system (code + model files). You can make different models for different airports.\n",
    "\n",
    "**Evaluation:** for every airport for every $k$ sMAPE will be calculated and averaged. General leaderboard will be calculated via Borda count. \n",
    "\n",
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import catboost\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare a model for set2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 00:01:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:02:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 00:03:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 00:04:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  num_orders\n",
       "0 2018-03-01 00:00:00           0\n",
       "1 2018-03-01 00:01:00           0\n",
       "2 2018-03-01 00:02:00           0\n",
       "3 2018-03-01 00:03:00           0\n",
       "4 2018-03-01 00:04:00           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нужно редактировать под каждую из задач: A, B и C\n",
    "\n",
    "set_name = 'set1'\n",
    "path_train_set = '../../data/train/{}.csv'.format(set_name)\n",
    "\n",
    "data = pd.read_csv(path_train_set)\n",
    "data.datetime = data.datetime.apply(\n",
    "    lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "data = data.sort_values('datetime')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict position for set2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_positions = {\n",
    "    'set1': [10, 30, 45, 60, 75],\n",
    "    'set2': [5, 10, 15, 20, 25],\n",
    "    'set3': [5, 7, 9, 11, 13]\n",
    "}[set_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUR_IN_MINUTES = 60\n",
    "DAY_IN_MINUTES = 24 * HOUR_IN_MINUTES\n",
    "WEEK_IN_MINUTES = 7 * DAY_IN_MINUTES\n",
    "\n",
    "MAX_TIME = DAY_IN_MINUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train samples with targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only history of orders (count of orders in every minutes) but we need to predict time of k orders since current minutes. So we should calculate target for train set. Also we will make a lot of samples from all set (we can only use two weeks of history while prediction so we can use only two weeks in every train sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "    'datetime': [],\n",
    "    'history': []}\n",
    "\n",
    "for position in target_positions:\n",
    "    samples['target_{}'.format(position)] = []\n",
    "    \n",
    "num_orders = data.num_orders.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate target (minutes before k orders) we are going to use cumulative sum of orders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start after 2 weeks because of history\n",
    "# finish earlier because of target calculation\n",
    "for i in range(2 * WEEK_IN_MINUTES,\n",
    "               len(num_orders) - 2 * DAY_IN_MINUTES):\n",
    "    \n",
    "    samples['datetime'].append(data.datetime[i])\n",
    "    samples['history'].append(num_orders[i-2*WEEK_IN_MINUTES:i])\n",
    "    \n",
    "    # cumsum not for all array because of time economy\n",
    "    cumsum_num_orders = num_orders[i+1:i+1+2*DAY_IN_MINUTES].cumsum()\n",
    "    for position in target_positions:\n",
    "        orders_by_positions = np.where(cumsum_num_orders >= position)[0]\n",
    "        if len(orders_by_positions):\n",
    "            time = orders_by_positions[0] + 1\n",
    "        else:\n",
    "            # if no orders in last days\n",
    "            time = MAX_TIME\n",
    "        samples['target_{}'.format(position)].append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pandas.dataframe. Now we have targets to train and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>history</th>\n",
       "      <th>target_10</th>\n",
       "      <th>target_30</th>\n",
       "      <th>target_45</th>\n",
       "      <th>target_60</th>\n",
       "      <th>target_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-15 00:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-15 00:01:00</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-15 00:02:00</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-15 00:03:00</td>\n",
       "      <td>[0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, 3, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-15 00:04:00</td>\n",
       "      <td>[1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, 3, 1, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                            history  \\\n",
       "0 2018-03-15 00:00:00  [0, 0, 0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, ...   \n",
       "1 2018-03-15 00:01:00  [0, 0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, ...   \n",
       "2 2018-03-15 00:02:00  [0, 0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, ...   \n",
       "3 2018-03-15 00:03:00  [0, 1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, 3, ...   \n",
       "4 2018-03-15 00:04:00  [1, 2, 0, 1, 1, 4, 0, 1, 1, 1, 1, 3, 2, 3, 1, ...   \n",
       "\n",
       "   target_10  target_30  target_45  target_60  target_75  \n",
       "0          5         18         28         32         42  \n",
       "1          5         19         27         32         42  \n",
       "2          7         20         27         33         43  \n",
       "3          7         21         26         35         42  \n",
       "4          7         20         26         35         42  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(samples)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate simple features.\n",
    "\n",
    "By time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df.datetime.apply(lambda x: x.weekday())\n",
    "df['hour'] = df.datetime.apply(lambda x: x.hour)\n",
    "df['minute'] = df.datetime.apply(lambda x: x.minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregators by order history with different shift and window size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFTS = [\n",
    "    HOUR_IN_MINUTES // 4,\n",
    "    HOUR_IN_MINUTES // 2,\n",
    "    HOUR_IN_MINUTES,\n",
    "    DAY_IN_MINUTES,\n",
    "    DAY_IN_MINUTES * 2,\n",
    "    WEEK_IN_MINUTES,\n",
    "    WEEK_IN_MINUTES * 2\n",
    "]\n",
    "\n",
    "WINDOWS = [\n",
    "    HOUR_IN_MINUTES // 4,\n",
    "    HOUR_IN_MINUTES // 2,\n",
    "    HOUR_IN_MINUTES,\n",
    "    DAY_IN_MINUTES,\n",
    "    DAY_IN_MINUTES * 2,\n",
    "    WEEK_IN_MINUTES,\n",
    "    WEEK_IN_MINUTES * 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift in SHIFTS:\n",
    "    for window in WINDOWS:\n",
    "        if window >= shift:\n",
    "            continue\n",
    "        df['num_orders_{}_{}'.format(shift, window)] = \\\n",
    "            df.history.apply(lambda x: x[-shift : -shift + window].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWINDOWS2 = np.ceil(df.loc[:, df.columns.str.startswith(\"target_\")].mean(axis=0)).astype(int).tolist()\\n\\nfor shift in SHIFTS:\\n    for window in WINDOWS2:\\n        if window >= shift:\\n            continue\\n        df[\\'num_orders_{}_{}\\'.format(shift, window)] =             df.history.apply(lambda x: x[-shift : -shift + window].sum())\\n\\nWINDOWS2\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ухудшает модель\n",
    "\n",
    "\"\"\"\n",
    "WINDOWS2 = np.ceil(df.loc[:, df.columns.str.startswith(\"target_\")].mean(axis=0)).astype(int).tolist()\n",
    "\n",
    "for shift in SHIFTS:\n",
    "    for window in WINDOWS2:\n",
    "        if window >= shift:\n",
    "            continue\n",
    "        df['num_orders_{}_{}'.format(shift, window)] = \\\n",
    "            df.history.apply(lambda x: x[-shift : -shift + window].sum())\n",
    "\n",
    "WINDOWS2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['num_orders_{}_{}'.format(shift, window)\n",
    "#                  for shift in SHIFTS for window in WINDOWS2 if window < shift],\n",
    "#         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target(history, prefix, count_first=True):\n",
    "    values = {}\n",
    "    \n",
    "    cumsum_num_orders = history[:2 * DAY_IN_MINUTES].cumsum()\n",
    "    \n",
    "    variants = target_positions\n",
    "    if count_first:\n",
    "        variants = [1] + variants\n",
    "    \n",
    "    for position in variants:\n",
    "        orders_by_positions = np.where(cumsum_num_orders >= position)[0]\n",
    "        if len(orders_by_positions):\n",
    "            time = orders_by_positions[0] + 1\n",
    "        else:\n",
    "            time = MAX_TIME\n",
    "        values['{}_{}'.format(prefix, position)] = time\n",
    "\n",
    "    return pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_features_history_1(history):\n",
    "    return compute_target(history[::-1], prefix=\"order_last\", count_first=True)\n",
    "\n",
    "df = df.merge(df.history.apply(extra_features_history_1), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_features_history_2(history):\n",
    "    return compute_target(history[WEEK_IN_MINUTES:], prefix=\"order_middle_1week\", count_first=False)\n",
    "\n",
    "df = df.merge(df.history.apply(extra_features_history_2), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_features_history_3(history):\n",
    "    return compute_target(history, prefix=\"order_middle_2week\", count_first=False)\n",
    "\n",
    "df = df.merge(df.history.apply(extra_features_history_3), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_features_history_4(history):\n",
    "    return compute_target(history[-DAY_IN_MINUTES:], prefix=\"order_middle_1day\", count_first=False)\n",
    "\n",
    "df = df.merge(df.history.apply(extra_features_history_4), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ухудшает модель\n",
    "\n",
    "def extra_features_history_5(history):\n",
    "    return compute_target(history[-2 * DAY_IN_MINUTES:], prefix=\"order_middle_2day\", count_first=False)\n",
    "\n",
    "# df = df.merge(df.history.apply(extra_features_history_5), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=df.columns[df.columns.str.startswith('order_middle_2day_')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дают небольшое улучшение, которое можно списать на шум\n",
    "\n",
    "def extra_features_history_6(history):\n",
    "    return compute_target(history[-3 * DAY_IN_MINUTES:], prefix=\"order_middle_3day\", count_first=False)\n",
    "\n",
    "df = df.merge(df.history.apply(extra_features_history_6), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=df.columns[df.columns.str.startswith('order_middle_3day_')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_empty_window(history, prefix):\n",
    "    res = np.nonzero(history)[0]\n",
    "    res = res[1:] - res[:-1]\n",
    "    return pd.Series({\n",
    "        \"{}_min\".format(prefix) : res.min() if len(res) else np.nan,\n",
    "        \"{}_max\".format(prefix) : res.max() if len(res) else np.nan,\n",
    "        \"{}_med\".format(prefix) : np.median(res) if len(res) else np.nan,\n",
    "        \"{}_num\".format(prefix) : res.shape[0],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дают небольшое улучшение, которое можно списать на шум\n",
    "\n",
    "def max_empty_stats_1(history):\n",
    "    return max_empty_window(history[-HOUR_IN_MINUTES:], \"max_empty_stats_1hour\")\n",
    "\n",
    "df = df.merge(df.history.apply(max_empty_stats_1), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дают небольшое улучшение, которое можно списать на шум\n",
    "\n",
    "def max_empty_stats_2(history):\n",
    "    return max_empty_window(history[-2 * HOUR_IN_MINUTES:], \"max_empty_stats_2hour\")\n",
    "\n",
    "df = df.merge(df.history.apply(max_empty_stats_2), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дают небольшое улучшение, которое можно списать на шум\n",
    "\n",
    "def max_empty_stats_3(history):\n",
    "    return max_empty_window(history[-HOUR_IN_MINUTES // 2:], \"max_empty_stats_30min\")\n",
    "\n",
    "df = df.merge(df.history.apply(max_empty_stats_3), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дают небольшое улучшение, которое можно списать на шум\n",
    "\n",
    "def max_empty_stats_4(history):\n",
    "    return max_empty_window(history[-WEEK_IN_MINUTES-HOUR_IN_MINUTES:\n",
    "                                    -WEEK_IN_MINUTES+HOUR_IN_MINUTES], \"max_empty_stats_middle_2hour\")\n",
    "\n",
    "df = df.merge(df.history.apply(max_empty_stats_4), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=df.columns[df.columns.str.startswith('max_empty_stats_')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = {\n",
    "    '01-01': {'holiday', 'dayoff'},\n",
    "    '01-02': {'dayoff'},\n",
    "    '01-03': {'dayoff'},\n",
    "    '01-04': {'dayoff'},\n",
    "    '01-05': {'dayoff'},\n",
    "    '01-06': {'dayoff'},\n",
    "    '01-07': {'holiday', 'dayoff'},\n",
    "    '02-23': {'holiday', 'dayoff'},\n",
    "    '02-24': {'dayoff'},\n",
    "    '03-08': {'holiday', 'dayoff'},\n",
    "    '05-01': {'holiday', 'dayoff'},\n",
    "    '05-08': {'dayoff'},\n",
    "    '05-09': {'holiday', 'dayoff'},\n",
    "    '11-06': {'dayoff'},\n",
    "    '12-31': {'holiday', 'dayoff'}\n",
    "}\n",
    "\n",
    "holidays_good_arrive = {\n",
    "    '01-01': {'holiday', 'dayoff'},\n",
    "    '01-02': {'dayoff'},\n",
    "    '02-22': {'holiday', 'dayoff'},\n",
    "    '02-23': {'holiday', 'dayoff'},\n",
    "    '03-07': {'holiday', 'dayoff'},\n",
    "    '03-08': {'holiday', 'dayoff'},\n",
    "    '05-01': {'holiday', 'dayoff'},\n",
    "    '04-31': {'holiday', 'dayoff'},\n",
    "    '05-02': {'holiday', 'dayoff'},\n",
    "    '05-08': {'dayoff'},\n",
    "    '05-09': {'holiday', 'dayoff'},\n",
    "    '11-06': {'dayoff'},\n",
    "    '12-31': {'holiday', 'dayoff'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday'] = df.datetime.apply(lambda x: '{:%m-%d}'.format(x) in holidays)\n",
    "df['good_arrive'] = df.datetime.apply(lambda x: '{:%m-%d}'.format(x) in holidays_good_arrive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_std_sum(history, shift, duration):\n",
    "    return np.std(np.sum(history.reshape(-1, shift)[:, -duration:], axis = 1))\n",
    "\n",
    "for position in target_positions:\n",
    "    df['sum_std_day_' + str(position)] = \\\n",
    "        df.apply(lambda r: count_std_sum(r['history'], 60 * 24,\n",
    "                                         r['order_last_'+str(position)]),\n",
    "                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'history', 'target_10', 'target_30', 'target_45',\n",
       "       'target_60', 'target_75', 'weekday', 'hour', 'minute',\n",
       "       'num_orders_30_15', 'num_orders_60_15', 'num_orders_60_30',\n",
       "       'num_orders_1440_15', 'num_orders_1440_30', 'num_orders_1440_60',\n",
       "       'num_orders_2880_15', 'num_orders_2880_30', 'num_orders_2880_60',\n",
       "       'num_orders_2880_1440', 'num_orders_10080_15', 'num_orders_10080_30',\n",
       "       'num_orders_10080_60', 'num_orders_10080_1440', 'num_orders_10080_2880',\n",
       "       'num_orders_20160_15', 'num_orders_20160_30', 'num_orders_20160_60',\n",
       "       'num_orders_20160_1440', 'num_orders_20160_2880',\n",
       "       'num_orders_20160_10080', 'order_last_1', 'order_last_10',\n",
       "       'order_last_30', 'order_last_45', 'order_last_60', 'order_last_75',\n",
       "       'order_middle_1week_10', 'order_middle_1week_30',\n",
       "       'order_middle_1week_45', 'order_middle_1week_60',\n",
       "       'order_middle_1week_75', 'order_middle_2week_10',\n",
       "       'order_middle_2week_30', 'order_middle_2week_45',\n",
       "       'order_middle_2week_60', 'order_middle_2week_75',\n",
       "       'order_middle_1day_10', 'order_middle_1day_30', 'order_middle_1day_45',\n",
       "       'order_middle_1day_60', 'order_middle_1day_75', 'order_middle_3day_10',\n",
       "       'order_middle_3day_30', 'order_middle_3day_45', 'order_middle_3day_60',\n",
       "       'order_middle_3day_75', 'max_empty_stats_1hour_min',\n",
       "       'max_empty_stats_1hour_max', 'max_empty_stats_1hour_med',\n",
       "       'max_empty_stats_1hour_num', 'max_empty_stats_2hour_min',\n",
       "       'max_empty_stats_2hour_max', 'max_empty_stats_2hour_med',\n",
       "       'max_empty_stats_2hour_num', 'max_empty_stats_30min_min',\n",
       "       'max_empty_stats_30min_max', 'max_empty_stats_30min_med',\n",
       "       'max_empty_stats_30min_num', 'max_empty_stats_middle_2hour_min',\n",
       "       'max_empty_stats_middle_2hour_max', 'max_empty_stats_middle_2hour_med',\n",
       "       'max_empty_stats_middle_2hour_num', 'holiday', 'good_arrive',\n",
       "       'sum_std_day_10', 'sum_std_day_30', 'sum_std_day_45', 'sum_std_day_60',\n",
       "       'sum_std_day_75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['datetime', 'history']).to_hdf('prepared_data/train_{}.hdf'.format(set_name), 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/validation split for time. Let's use last 4 weeks for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-03-15 00:00:00'), Timestamp('2018-08-29 23:59:00'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.datetime.min(), df.datetime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df.datetime <= df.datetime.max() - datetime.timedelta(days=28)]\n",
    "df_valid = df.loc[df.datetime  > df.datetime.max() - datetime.timedelta(days=28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df\n",
    "df_valid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weekday',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'num_orders_30_15',\n",
       " 'num_orders_60_15',\n",
       " 'num_orders_60_30',\n",
       " 'num_orders_1440_15',\n",
       " 'num_orders_1440_30',\n",
       " 'num_orders_1440_60',\n",
       " 'num_orders_2880_15',\n",
       " 'num_orders_2880_30',\n",
       " 'num_orders_2880_60',\n",
       " 'num_orders_2880_1440',\n",
       " 'num_orders_10080_15',\n",
       " 'num_orders_10080_30',\n",
       " 'num_orders_10080_60',\n",
       " 'num_orders_10080_1440',\n",
       " 'num_orders_10080_2880',\n",
       " 'num_orders_20160_15',\n",
       " 'num_orders_20160_30',\n",
       " 'num_orders_20160_60',\n",
       " 'num_orders_20160_1440',\n",
       " 'num_orders_20160_2880',\n",
       " 'num_orders_20160_10080',\n",
       " 'order_last_1',\n",
       " 'order_last_10',\n",
       " 'order_last_30',\n",
       " 'order_last_45',\n",
       " 'order_last_60',\n",
       " 'order_last_75',\n",
       " 'order_middle_1week_10',\n",
       " 'order_middle_1week_30',\n",
       " 'order_middle_1week_45',\n",
       " 'order_middle_1week_60',\n",
       " 'order_middle_1week_75',\n",
       " 'order_middle_2week_10',\n",
       " 'order_middle_2week_30',\n",
       " 'order_middle_2week_45',\n",
       " 'order_middle_2week_60',\n",
       " 'order_middle_2week_75',\n",
       " 'order_middle_1day_10',\n",
       " 'order_middle_1day_30',\n",
       " 'order_middle_1day_45',\n",
       " 'order_middle_1day_60',\n",
       " 'order_middle_1day_75',\n",
       " 'order_middle_3day_10',\n",
       " 'order_middle_3day_30',\n",
       " 'order_middle_3day_45',\n",
       " 'order_middle_3day_60',\n",
       " 'order_middle_3day_75',\n",
       " 'max_empty_stats_1hour_min',\n",
       " 'max_empty_stats_1hour_max',\n",
       " 'max_empty_stats_1hour_med',\n",
       " 'max_empty_stats_1hour_num',\n",
       " 'max_empty_stats_2hour_min',\n",
       " 'max_empty_stats_2hour_max',\n",
       " 'max_empty_stats_2hour_med',\n",
       " 'max_empty_stats_2hour_num',\n",
       " 'max_empty_stats_30min_min',\n",
       " 'max_empty_stats_30min_max',\n",
       " 'max_empty_stats_30min_med',\n",
       " 'max_empty_stats_30min_num',\n",
       " 'max_empty_stats_middle_2hour_min',\n",
       " 'max_empty_stats_middle_2hour_max',\n",
       " 'max_empty_stats_middle_2hour_med',\n",
       " 'max_empty_stats_middle_2hour_num',\n",
       " 'holiday',\n",
       " 'good_arrive',\n",
       " 'sum_std_day_10',\n",
       " 'sum_std_day_30',\n",
       " 'sum_std_day_45',\n",
       " 'sum_std_day_60',\n",
       " 'sum_std_day_75']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "mask = reduce(operator.or_, [\n",
    "    df.columns.str.startswith('target_'),\n",
    "    [c in {'datetime', 'history'} for c in df.columns],\n",
    "])\n",
    "\n",
    "features = df.columns[~mask].tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(y_true, y_pred, shift=0):\n",
    "    return 2 * np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we will save models for prediction stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "model_to_save = { 'models': defaultdict(list) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is good or bad model? We can compare our model with constant solution. For instance median (optimal solution for MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds: 1925 7354 7914 4109 2190 5034 4521\n",
      "\n",
      "target_10\n",
      "sMAPE = 0.256709\n",
      "sMAPE = 0.260811\n",
      "sMAPE = 0.261517\n",
      "sMAPE = 0.260346\n",
      "sMAPE = 0.259740\n",
      "sMAPE = 0.257021\n",
      "sMAPE = 0.258760\n",
      "MEAN: 0.25927197475176866 \n",
      "\n",
      "target_30\n",
      "sMAPE = 0.180635\n",
      "sMAPE = 0.182041\n",
      "sMAPE = 0.179706\n",
      "sMAPE = 0.181051\n",
      "sMAPE = 0.180349\n",
      "sMAPE = 0.183305\n",
      "sMAPE = 0.181989\n",
      "MEAN: 0.18129650870761618 \n",
      "\n",
      "target_45\n",
      "sMAPE = 0.157164\n",
      "sMAPE = 0.159177\n",
      "sMAPE = 0.156611\n",
      "sMAPE = 0.157615\n",
      "sMAPE = 0.157101\n",
      "sMAPE = 0.157755\n",
      "sMAPE = 0.157454\n",
      "MEAN: 0.1575538466018225 \n",
      "\n",
      "target_60\n",
      "sMAPE = 0.141071\n",
      "sMAPE = 0.141734\n",
      "sMAPE = 0.139956\n",
      "sMAPE = 0.140946\n",
      "sMAPE = 0.140000\n",
      "sMAPE = 0.141290\n",
      "sMAPE = 0.141297\n",
      "MEAN: 0.14089907624568915 \n",
      "\n",
      "target_75\n",
      "sMAPE = 0.128621\n",
      "sMAPE = 0.129374\n",
      "sMAPE = 0.127476\n",
      "sMAPE = 0.128458\n",
      "sMAPE = 0.128107\n",
      "sMAPE = 0.127447\n",
      "sMAPE = 0.129331\n",
      "MEAN: 0.12840201419379618 \n",
      "\n",
      "CPU times: user 53min 54s, sys: 16min 49s, total: 1h 10min 44s\n",
      "Wall time: 24min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_pos = []\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=4986)\n",
    "\n",
    "np.random.seed(5872)\n",
    "seeds = np.random.randint(1_000, 10_000, size=7)\n",
    "print(\"seeds:\", *seeds, end='\\n\\n')\n",
    "\n",
    "cat_features = [\n",
    "    df_train.columns.tolist().index('weekday'),\n",
    "    df_train.columns.tolist().index('hour')\n",
    "]\n",
    "\n",
    "for position in target_positions:\n",
    "    position_t = 'target_{}'.format(position)\n",
    "    print(position_t)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    for train_i, valid_i in kf.split(df_train):        \n",
    "        X_train, y_train = df_train.loc[train_i, features], df_train.loc[train_i, position_t]\n",
    "        X_valid, y_valid = df_train.loc[valid_i, features], df_train.loc[valid_i, position_t]\n",
    "        \n",
    "        model = catboost.CatBoostRegressor(\n",
    "            iterations=2000, learning_rate=1.0, random_state=seeds[steps],\n",
    "            loss_function='MAE', task_type='GPU', devices='3'\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, cat_features=cat_features,\n",
    "                  use_best_model=True, eval_set=(X_valid, y_valid), verbose=False)\n",
    "        \n",
    "        if df_valid is not None:\n",
    "            X_valid, y_valid = df_valid.loc[:, features], df_valid.loc[:, position_t]\n",
    "            \n",
    "        y_pred = model.predict(X_valid)\n",
    "        score = sMAPE(y_valid, y_pred)\n",
    "        print('sMAPE = {:.6f}'.format(score))\n",
    "        scores.append(score)\n",
    "    \n",
    "        model_to_save['models'][position].append(model)\n",
    "        steps += 1\n",
    "    \n",
    "    score = np.mean(scores)\n",
    "    print('MEAN:', score, '\\n')\n",
    "    score_pos.append(score)\n",
    "    \n",
    "score_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17348468410013854"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is better than constant solution. Saving model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_to_save, open('models-{}.pkl'.format(set_name), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
